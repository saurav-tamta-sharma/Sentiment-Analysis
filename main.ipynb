{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     target                                               text  \\\n",
      "0  negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1  negative  is upset that he can't update his Facebook by ...   \n",
      "2  negative  @Kenichan I dived many times for the ball. Man...   \n",
      "3  negative    my whole body feels itchy and like its on fire    \n",
      "4  negative  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0    - a that's a bummer.  you shoulda got david ...  \n",
      "1  is upset that he can't update his facebook by ...  \n",
      "2   i dived many times for the ball. managed to s...  \n",
      "3    my whole body feels itchy and like its on fire   \n",
      "4   no, it's not behaving at all. i'm mad. why am...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('sentiment_dataset.csv', encoding='latin-1', header=None)\n",
    "data.columns = ['target', 'id', 'date', 'flag', 'user', 'text']\n",
    "\n",
    "# Filter necessary columns\n",
    "data = data[['target', 'text']]\n",
    "data['target'] = data['target'].map({0: 'negative', 4: 'positive'})\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text)  # Remove @ mentions\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text)  # Remove hashtags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = text.lower()  # Convert to lowercasees\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spac\n",
    "data['cleaned_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Display sample data\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Split the dataset\n",
    "X = data['cleaned_text']\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saura\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79048125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.78      0.79    159494\n",
      "    positive       0.78      0.80      0.79    160506\n",
      "\n",
      "    accuracy                           0.79    320000\n",
      "   macro avg       0.79      0.79      0.79    320000\n",
      "weighted avg       0.79      0.79      0.79    320000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'sentiment_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
